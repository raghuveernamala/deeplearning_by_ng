{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Welcome to your last programming assignment of Course 5. You will build a Neural Machine Translation (NMT) model to translate human readable dates (\"25th of June, 2009\") into machine readable dates (\"2009-06-25\"). After building a working Encoder-Decoder recurrent neural network, you are going to augment your model by adding attention mechanisms.\n",
    "\n",
    "This notebook has been jointly produced by deeplearning.ai and NVIDIA's Deep Learning Institute (DLI).\n",
    "\n",
    "Let's load all the packages you will need in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.backend import int_shape\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Translating human readable dates in machine readable dates\n",
    "\n",
    "Although it is usually used to translate sentences from a source language (*e.g. Arabic*) to a target language (*e.g. Hindi*), Neural Machine Translation (NMT) has a wider range of applications. In this notebook, you are going to build an NMT to translate human readable dates (*e.g. \"the 29th of August 1958\", \"03/30/1968\", \"24 JUNE 1987\"*) into machine readable dates (*e.g. \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset\n",
    "\n",
    "The dataset is a corpus of 1000 human readable dates and their equivalent machine readable dates. Let's run the following cell to load the dataset and print some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 7627.62it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab, sources, targets = create_dataset(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- dataset: a list of tuples (human readable date, machine readable date)\n",
    "- human_vocab: a python dictionary mapping all characters used in human readable dates to an index (integer values)\n",
    "- machine_vocab: a python dictionary mapping all characters used in machine readable dates to an index (integer values)\n",
    "- inv_machine_vocab: the inverse dictionary of `machine_vocab`\n",
    "- sources: a processed version of dataset's human readable dates, where each character is replaced by the integer value it is mapped to in the human_vocab, padded to $T_x$ values. `sources.shape = (m, Tx)`\n",
    "- targets: a processed version of dataset's machine readable dates, where each character is replaced by the one-hot vector of the character it is mapped to in the machine_vocab, the date is also padded up to $T_x$. `targets.shape = (m, Tx, len(machine_vocab))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the index in the cell below to navigate in the dataset and see how source/target dates are preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 10/8/87\n",
      "Target date: 1987-10-08\n",
      "\n",
      "Source after preprocessing: [25 48 17 23 17 23 40 59 59 59 59 59 59 59 59 59 59 59 59 59]\n",
      "Target after preprocessing: [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing:\", sources[index])\n",
    "print(\"Target after preprocessing:\", targets[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2 - Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your NMT will use an encoder-decoder architecture. One training example's run through the model is explained in the figures below.\n",
    "\n",
    "<img src=\"images/enc.png\" style=\"width:600;height:300px;\"> <br>\n",
    "<caption><center> **Figure 1**: Simple NMT model (encoder part) </center></caption>\n",
    "\n",
    "First, a preprocessed source date is encoded using a Bi-directional LSTM. The sequence of hidden states are returned and stored in an object called `enc_out`. `enc_out` is then given as an input sequence to the decoder which is described in the figure below.\n",
    "\n",
    "<img src=\"images/dec.png\" style=\"width:500;height:300px;\"> <br>\n",
    "<caption><center> **Figure 2**: Simple NMT model (decoder part) </center></caption>\n",
    "\n",
    "The output vectors can then be compared to the ground truth using a categorical cross-entropy loss function. Minimizing this loss function will give you a trained NMT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement the `model_simple_nmt()` described in the figure below. The LSTMs both use 32 units. The embedding layer outputs a 64-dimensional embedding and should be trainable. These functions might be useful: Input(), [Embedding()](https://keras.io/layers/embeddings/), [LSTM()](https://keras.io/layers/recurrent/#lstm), [Bidirectional()](), [Dense()](https://keras.io/layers/core/#dense), [TimeDistributed()](https://keras.io/layers/wrappers/#timedistributed), [Model()](https://keras.io/models/model/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_simple_nmt(human_vocab_size, machine_vocab_size, Tx = 20):\n",
    "    \"\"\"\n",
    "    Simple Neural Machine Translation model\n",
    "    \n",
    "    Arguments:\n",
    "    human_vocab_size -- size of the human vocabulary for dates, it will give us the size of the embedding layer\n",
    "    machine_vocab_size -- size of the machine vocabulary for dates, it will give us the size of the output vector\n",
    "    \n",
    "    Returns:\n",
    "    model -- model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx,))\n",
    "    \n",
    "    # Define the embedding layer. This layer should be trainable and the input_length should be set to Tx.\n",
    "    input_embed = Embedding(human_vocab_size, 2*32, input_length = Tx, trainable=True)(inputs)\n",
    "    \n",
    "    # Encode the embeddings using a bidirectional LSTM\n",
    "    enc_out = Bidirectional(LSTM(32, return_sequences=True))(input_embed)\n",
    "    \n",
    "    # Decode the encoding using an LSTM layer\n",
    "    dec_out = LSTM(32, return_sequences=True)(enc_out)\n",
    "    \n",
    "    # Apply Dense layer to every time steps\n",
    "    output = TimeDistributed(Dense(machine_vocab_size, activation='softmax'))(dec_out)\n",
    "    \n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to create your `model` and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:30: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ti...)`\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's train this model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "900/900 [==============================] - 6s - loss: 1.6355 - acc: 0.5147 - val_loss: 1.2057 - val_acc: 0.5850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f5ecd96d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([sources], targets, epochs=1, batch_size=12, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.4 - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your simple NMT model on various examples using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3rd of March 2001\n",
      "output: 0000000--<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈1 line)\n",
    "example = \"3rd of March 2001\"\n",
    "### END CODE HERE ###\n",
    "source = string_to_int(example, 20, human_vocab)\n",
    "prediction = model.predict(np.array([source]))\n",
    "prediction = np.argmax(prediction[0], axis = -1)\n",
    "output = int_to_string(prediction, inv_machine_vocab)\n",
    "print(\"source:\", example)\n",
    "print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, your NMT makes many mistakes, specially on long source dates such as *\"3rd of March 1834\"*. To overcome this, you are going to add an attention mechanism to your NMT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Improving results using attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had to translate a book's paragraph from French to English, you would not read the whole paragraph then close the book and translate. You would first read the paragraph. Then, while translating, you would read and focus on parts of the paragraph corresponding to the parts you are currently translating.\n",
    "\n",
    "Attention mechanism is technique in Deep Learning to help the model drive its focus on important parts of the input. In this part, you will augment your simple NMT with attention. \n",
    "\n",
    "### 2.1 - Attention models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Concretely, after running a source date in the encoder (Bi-LSTM), you would like to give all the hidden states to the decoder to get back the target date. However, at every step in the decoding process, you'd like your model to be able to tell which hidden state is more important to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[TEXT + FORMULAS + IMAGE PRESENTING THIS ATTENTION_3D_BLOCK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    \"\"\"\n",
    "    Implement the attention block applied between two layers\n",
    "    \n",
    "    Argument:\n",
    "    inputs -- output of the previous layer, set of hidden states\n",
    "    \n",
    "    Returns:\n",
    "    output_attention_mul -- inputs weighted with attention probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve n_h and Tx from inputs' shape. Recall: inputs.shape = (m, Tx, n_h)\n",
    "    Tx = int_shape(inputs)[1]\n",
    "    n_h = int_shape(inputs)[2]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Permute inputs' columns to compute \"a\" of shape (m, n_h, Tx)\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    \n",
    "    # Apply a Dense layer with softmax activation. It should contain Tx neurons. a.shape should still be (m, n_h, Tx).\n",
    "    a = Dense(Tx, activation='softmax')(a)\n",
    "    \n",
    "    # Compute the mean of \"a\" over axis=1 (the \"hidden\" axis: n_h). a.shape should now be (m, Tx)\n",
    "    a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    \n",
    "    # Repeat the vector \"a\" n_h times. \"a\" should now be of shape (m, n_h, Tx)\n",
    "    a = RepeatVector(n_h)(a)\n",
    "    \n",
    "    # Permute the 2nd and the first column of a to get a probability vector of attention. a_probs.shape = (m, Tx, n_h)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    \n",
    "    # Apply the attention probabilities to the \"inputs\" by multiplying element-wise.\n",
    "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n_h = 5\n",
    "Tx = 2\n",
    "m = 1\n",
    "with tf.Session() as sess:\n",
    "    \"\"\"\n",
    "    inputs = tf.Variable(np.random.randn(m,Tx,n_h))\n",
    "    print(inputs.shape) # m,Tx,n_h\n",
    "    a = Permute((2,1))(inputs)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(a))\n",
    "    a = Reshape((n_h, Tx))(a)\n",
    "    #print(sess.run(a))\n",
    "    #a = Dense(Tx, activation='softmax')(a)\n",
    "    #print(a.shape, \"A\") # m, n_h, Tx\n",
    "    a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    print(a.shape, \"B\") # m, Tx\n",
    "    a = RepeatVector(n_h)(a)\n",
    "    print(a.shape) # m, n_h, Tx\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    print(a_probs.shape, \"C\") # m, Tx, n_h\n",
    "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
    "    print(output_attention_mul.shape) # m, Tx, n_h\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Assessing the efficiency of this attention block\n",
    "\n",
    "In order to ensure that the activation block you have just coded is able to tell the model where to focus on, you are going to try an experiment.\n",
    "\n",
    "Let's first generate datapoints $(X, Y) = $ {$(x^{(i)}, y^{(i)})_{i=1...m}$} such that:\n",
    "- $y^{(i)}$ is a label equal to 0 or 1.\n",
    "- $x^{(i)}$ is a matrix of shape $(T_x, n_h)$ where one column is equal to $y^{(i)}$  and the rest is random. It means that for some time-step \"t\", we have x[t,:] = y.\n",
    "- Thus `X.shape =` $(m, T_x, n_h)$ and `Y.shape =` $(m, 1)$.\n",
    "\n",
    "Run the cell below to see some examples of X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (2, 4, 3)\n",
      "x = [[[-0.54974618 -1.40287272  1.5827523 ]\n",
      "  [ 1.          1.          1.        ]\n",
      "  [-1.50780766 -0.31529207  0.85817886]\n",
      "  [ 0.07134299 -2.29230928 -1.41555249]]\n",
      "\n",
      " [[ 0.8858294   0.63190187  0.04026035]\n",
      "  [ 1.          1.          1.        ]\n",
      "  [-0.53524902  0.77735121  0.17133845]\n",
      "  [-0.44285144  1.70490377  0.92434585]]]\n",
      "\n",
      "y.shape = (2, 1)\n",
      "y = [[1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x, y = get_data_recurrent(m = 2, Tx = 4, n_h = 3, attention_column=None)\n",
    "print(\"x.shape =\", x.shape)\n",
    "print(\"x =\", x)\n",
    "print()\n",
    "print(\"y.shape =\", y.shape)\n",
    "print(\"y =\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset (X, Y) is useful to observe the impact of attention. Indeed, you will try a binary classifier that given x will predict y. Thanks to the attention mechanism, your network should understand that only one time-step of x is useful to predict y, the rest is random. Your model should focus solely on this particular time-step. Run the following cell to load the dataset with attention on the third time-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_data_recurrent(m = 10000, Tx = 10, n_h = 2, attention_column = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 - Attention after an LSTM\n",
    "\n",
    "The attention block can be mounted at different positions in the network. The most common positions are before and after an LSTM. Below, we are providing two different models with the attention block applied before and after the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm(Tx, n_h):\n",
    "    \"\"\"\n",
    "    Model with attention applied before the LSTM\n",
    "        \n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx, n_h,))\n",
    "    # Add the attention block\n",
    "    attention_mul = attention_3d_block(inputs)\n",
    "    # Pass the inputs in a LSTM layer, return the sequence of hidden states\n",
    "    attention_mul = LSTM(32, return_sequences=False)(attention_mul)\n",
    "    # Apply Dense layer with sigmoid activation the output should be a single number.\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_after_lstm(Tx, n_x):\n",
    "    \"\"\"\n",
    "    Model with attention applied after the LSTM\n",
    "    \n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx, n_x,))\n",
    "    # Pass the inputs in a LSTM layer, return the sequence of hidden states\n",
    "    lstm_out = LSTM(32, return_sequences=True)(inputs)\n",
    "    # Add the attention block\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    # Flatten the output of the attention block\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    # Apply Dense layer with sigmoid activation the output should be a single number.\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will train the model with attention applied after the LSTM. Later on, you can come back and try the model with attention applied before the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "m = model_attention_applied_after_lstm(Tx = 10, n_x = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to compile the model you've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell below will train your model over the (X, Y) dataset for 100 epochs and a batch size of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.3990 - acc: 0.8168 - val_loss: 0.3283 - val_acc: 0.8650\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.3416 - acc: 0.8528 - val_loss: 0.2831 - val_acc: 0.8910\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.3111 - acc: 0.8677 - val_loss: 0.2564 - val_acc: 0.9020\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.2881 - acc: 0.8761 - val_loss: 0.2318 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.2640 - acc: 0.8840 - val_loss: 0.2007 - val_acc: 0.9260\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.2304 - acc: 0.8994 - val_loss: 0.1712 - val_acc: 0.9360\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.1994 - acc: 0.9136 - val_loss: 0.1432 - val_acc: 0.9490\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.1686 - acc: 0.9300 - val_loss: 0.1199 - val_acc: 0.9630\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.1442 - acc: 0.9441 - val_loss: 0.1040 - val_acc: 0.9650\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 2s - loss: 0.1205 - acc: 0.9550 - val_loss: 0.0901 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ef1952da0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit([X], Y, epochs=10, batch_size=512, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if the attention actually works. Let's generate 200 training examples with `attention_column=3`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[@VALENTIN CAN YOU PLEASE CHECK IF THIS IS WORKING FOR YOU. IT DOESN'T WORK FOR ME, MY RESULTS ARE INCONSISTENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEFCAYAAADjUZCuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngpmZJU4IZmYGwP8HEzTmaxviGD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ef42894e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_vectors = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Generate one training example (x, y), the attention column can be on any time-step.\n",
    "    x, y = get_data_recurrent(m = 1, Tx = 10, n_h = 2)\n",
    "    # Extract the attention vector predicted by the model \"m\" on the training example \"x\".\n",
    "    attention_vector = np.mean(get_activations(m, x, layer_name='attention_vec')[0], axis=2).squeeze()\n",
    "    # Append the attention vector to the list of attention vectors\n",
    "    assert (np.sum(attention_vector) - 1.0) < 1e-5\n",
    "    attention_vectors.append(attention_vector)\n",
    "\n",
    "# Compute the average attention on every time-step\n",
    "attention_vector_final = np.mean(np.array(attention_vectors), axis=0)\n",
    "\n",
    "# Plot\n",
    "pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar', title='On which time step is the focus?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 - Adding Attention to your NTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to add attention to the NMT model you've implemented in part (1). \n",
    "\n",
    "**Exercise**: Re-implement `model_simple_nmt()` but this time with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_attention_nmt(human_vocab_size, machine_vocab_size, Tx = 20):\n",
    "    \"\"\"\n",
    "    Attention Neural Machine Translation model\n",
    "    \n",
    "    Arguments:\n",
    "    human_vocab_size -- size of the human vocabulary for dates, it will give us the size of the embedding layer\n",
    "    machine_vocab_size -- size of the machine vocabulary for dates, it will give us the size of the output vector\n",
    "    \n",
    "    Returns:\n",
    "    model -- model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx,))\n",
    "    \n",
    "    # Define the embedding layer. This layer should be trainable and the input_length should be set to Tx.\n",
    "    input_embed = Embedding(human_vocab_size, 2*32, input_length = Tx, trainable=True)(inputs)\n",
    "    \n",
    "    # Encode the embeddings using a bidirectional LSTM\n",
    "    enc_out = Bidirectional(LSTM(32, return_sequences=True))(input_embed)\n",
    "    \n",
    "    # Add attention\n",
    "    attention = attention_3d_block(enc_out)\n",
    "    \n",
    "    # Decode the encoding using an LSTM layer\n",
    "    dec_out = LSTM(32, return_sequences=True)(attention)\n",
    "    \n",
    "    # Apply Dense layer to every time steps\n",
    "    output = TimeDistributed(Dense(machine_vocab_size, activation='softmax'))(dec_out)\n",
    "    \n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CREATE MODEL + COMIPLING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model_att = model_attention_nmt(len(human_vocab), len(machine_vocab))\n",
    "\n",
    "# Compile model\n",
    "model_att.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TRAINING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_att.fit([sources], targets, epochs=1, batch_size=12, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈1 line)\n",
    "example = \"3rd of March 2001\"\n",
    "### END CODE HERE ###\n",
    "source = string_to_int(example, 20, human_vocab)\n",
    "prediction = model_att.predict(np.array([source]))\n",
    "prediction = np.argmax(prediction[0], axis = -1)\n",
    "output = int_to_string(prediction, inv_machine_vocab)\n",
    "print(\"source:\", example)\n",
    "print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Attention\n",
    "[VISUALIZING ATTENTION ON A FEW EXAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_map(model, input_vocabulary, inv_output_vocabulary, text):\n",
    "    \"\"\"\n",
    "        visualization of attention map\n",
    "    \"\"\"\n",
    "    # encode the string\n",
    "    encoded = string_to_int(text, Tx, input_vocabulary)\n",
    "\n",
    "    # get the output sequence\n",
    "    prediction = model.predict(np.array([encoded]))\n",
    "    predicted_text = np.argmax(prediction[0], axis=-1)\n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "\n",
    "    text_ = list(text)\n",
    "    # get the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = predicted_text.index('<pad>')\n",
    "    # get the activation map\n",
    "    attention_vector = get_activations(model, [encoded], layer_name='attention_vec')[0].squeeze()\n",
    "    activation_map = attention_vector[0:output_length, 0:input_length]\n",
    "    \n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(8, 8.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(activation_map, interpolation='nearest', cmap='gray')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Probability', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_map(model_att, human_vocab, inv_machine_vocab, EXAMPLES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - BLEU SCORE + BEAM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0033319 ]\n",
      " [ 0.59544504]\n",
      " [ 0.00413279]\n",
      " [ 0.00315457]\n",
      " [ 0.00271449]\n",
      " [ 0.00771692]\n",
      " [ 0.97968459]\n",
      " [ 0.00281642]\n",
      " [ 0.00265952]\n",
      " [ 0.00314108]] [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "10/10 [==============================] - 0s\n",
      " Test accuracy = 0.699999988079\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4)\n",
    "x, y = get_data_recurrent(m = 10, Tx = 10, n_h = 2, attention_column= 3)\n",
    "pred = m.predict(x)\n",
    "print(pred, y)\n",
    "acc = m.evaluate([x], y)[1]\n",
    "print(\" Test accuracy =\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, layer_name=None):\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_recurrent(n, time_steps, input_dim, attention_column=None):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param time_steps: the number of time steps of your series.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    if attention_column is None:\n",
    "        attention_column = np.random.randint(low=0, high=input_dim)\n",
    "    x = np.random.standard_normal(size=(n, time_steps, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column, :] = np.tile(y[:], (1, input_dim))\n",
    "    print(x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1, y1 = get_data_recurrent(2, 6, 5, attention_column=None)\n",
    "print(x1.shape)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 20\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nmt_with_attention(human_vocab_size, machine_vocab_size, Tx = 20):\n",
    "    \"\"\"\n",
    "    Simple Neural Machine Translation model\n",
    "    \n",
    "    Arguments:\n",
    "    human_vocab_size -- size of the human vocabulary for dates, it will give us the size of the embedding layer\n",
    "    machine_vocab_size -- size of the machine vocabulary for dates, it will give us the size of the output vector\n",
    "    \n",
    "    Returns:\n",
    "    model -- model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx,))\n",
    "    \n",
    "    # Define the embedding layer. This layer should be trainable and the input_length should be set to Tx.\n",
    "    input_embed = Embedding(human_vocab_size, 2*32, input_length = Tx, trainable=True)(inputs)\n",
    "    \n",
    "    # Encode the embeddings using a bidirectional LSTM\n",
    "    enc_out = Bidirectional(LSTM(32, return_sequences=True))(input_embed)\n",
    "    \n",
    "    # Decode the encoding using an LSTM layer\n",
    "    dec_out = LSTM(32, return_sequences=True)(enc_out)\n",
    "    \n",
    "    # Apply Dense layer to every time steps\n",
    "    output = TimeDistributed(Dense(machine_vocab_size, activation='softmax'))(dec_out)\n",
    "    \n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    \"\"\"\n",
    "    Adds attention to the given input\n",
    "    \n",
    "    Argument:\n",
    "    inputs --\n",
    "    \n",
    "    Returns:\n",
    "    output_attention_mul --\n",
    "    \n",
    "    \"\"\"\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, Tx))(a)\n",
    "    a = Dense(Tx, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_after_lstm():\n",
    "    \"\"\"\n",
    "    Model with attention applied after the LSTM\n",
    "    \n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx, INPUT_DIM,))\n",
    "    # Pass the inputs in a LSTM layer, return the sequence of hidden states\n",
    "    lstm_out = LSTM(32, return_sequences=True)(inputs)\n",
    "    # Add the attention block\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    # Flatten the output of the attention block\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    # Apply Dense layer with sigmoid activation the output should be a single number.\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_before_lstm():\n",
    "    \"\"\"\n",
    "    Model with attention applied before the LSTM\n",
    "        \n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape (Tx,)\n",
    "    inputs = Input(shape=(Tx, INPUT_DIM,))\n",
    "    # Add the attention block\n",
    "    attention_mul = attention_3d_block(inputs)\n",
    "    # Pass the inputs in a LSTM layer, return the sequence of hidden states\n",
    "    attention_mul = LSTM(32, return_sequences=False)(attention_mul)\n",
    "    # Apply Dense layer with sigmoid activation the output should be a single number.\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    # Create model instance \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000#300000\n",
    "INPUT_DIM = 2\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "\n",
    "inputs_1, outputs = get_data_recurrent(N, Tx, INPUT_DIM)\n",
    "\n",
    "if APPLY_ATTENTION_BEFORE_LSTM:\n",
    "    m = model_attention_applied_before_lstm()\n",
    "else:\n",
    "    m = model_attention_applied_after_lstm()\n",
    "\n",
    "m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3 - Check your attention model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit([inputs_1], outputs, epochs=1, batch_size=512, validation_split=0.1)\n",
    "\n",
    "attention_vectors = []\n",
    "for i in range(300):\n",
    "    testing_inputs_1, testing_outputs = get_data_recurrent(1, Tx, INPUT_DIM)\n",
    "    attention_vector = np.mean(get_activations(m,\n",
    "                                               testing_inputs_1,\n",
    "                                               layer_name='attention_vec')[0], axis=2).squeeze()\n",
    "    #print('attention =', attention_vector)\n",
    "    assert (np.sum(attention_vector) - 1.0) < 1e-5\n",
    "    attention_vectors.append(attention_vector)\n",
    "\n",
    "attention_vector_final = np.mean(np.array(attention_vectors), axis=0)\n",
    "\n",
    "# plot part.\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "pd.DataFrame(attention_vector_final, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                     title='Attention Mechanism as '\n",
    "                                                                           'a function of input'\n",
    "                                                                           ' dimensions.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4 - Implement Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "fake.seed(12345)\n",
    "random.seed(12345)\n",
    "\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_date():\n",
    "    \"\"\"\n",
    "        Creates some fake dates \n",
    "        :returns: tuple containing human readable string, machine readable string, and date object\n",
    "    \"\"\"\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(FORMATS), locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.choice([0,1,2])\n",
    "        if case_change == 1:\n",
    "            human_readable = human_readable.upper()\n",
    "        elif case_change == 2:\n",
    "            human_readable = human_readable.lower()\n",
    "        # if case_change == 0, do nothing\n",
    "\n",
    "        machine_readable = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_examples):\n",
    "    \"\"\"\n",
    "        Creates a dataset with n_examples and vocabularies\n",
    "        :n_examples: the number of examples to generate\n",
    "    \"\"\"\n",
    "    human_vocab = set()\n",
    "    machine_vocab = set()\n",
    "    dataset = []\n",
    "\n",
    "    for i in tqdm(range(n_examples)):\n",
    "        h, m, _ = create_date()\n",
    "        if h is not None:\n",
    "            dataset.append((h, m))\n",
    "            human_vocab.update(tuple(h))\n",
    "            machine_vocab.update(tuple(m))\n",
    "\n",
    "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
    "                     list(range(len(human_vocab) + 2))))\n",
    "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
    "    machine = {v:k for k,v in inv_machine.items()}\n",
    " \n",
    "    return dataset, human, machine, inv_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_to_int(string, lenght, vocab):\n",
    "    if len(string) > lenght:\n",
    "        string = string[:lenght]\n",
    "        \n",
    "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
    "    \n",
    "    if len(string) < lenght:\n",
    "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
    "    \n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int_to_string(ints, inv_vocab):\n",
    "    return [inv_vocab[i] for i in ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000 #300000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
    "\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, targets = zip(*dataset)\n",
    "inputs = np.array([string_to_int(i, Tx, human_vocab) for i in inputs])\n",
    "targets = [string_to_int(t, Tx, machine_vocab) for t in targets]\n",
    "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.fit([inputs], targets, epochs=1, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=human_vocab[\"<pad>\"], rnn_model=m, maxlen=30):\n",
    "    \"\"\"for every sample, calculate probability for every possible label\n",
    "    you need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty)\n",
    "    return rnn_model.predict(data, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll try to generate some dates out of our model to demostrate beam search properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beamsearch(predict=keras_rnn_predict, k=1, maxsample=10, \n",
    "               use_unk=False, \n",
    "               oov=human_vocab[\"<unk>\"], \n",
    "               empty=human_vocab[\"<pad>\"], \n",
    "               eos=human_vocab[\"<unk>\"]):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    \n",
    "    dead_k = 0 # samples that reached eos\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1 # samples that did not yet reached eos\n",
    "    live_samples = [[empty]]\n",
    "    live_scores = [0]\n",
    "\n",
    "    while live_k and dead_k < k:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        probs = predict(live_samples, empty=empty)\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        if not use_unk and oov is not None:\n",
    "            cand_scores[:,oov] = 1e20\n",
    "        cand_flat = cand_scores.flatten()\n",
    "\n",
    "        # find the best (lowest) scores we have from all possible samples and new words\n",
    "        ranks_flat = cand_flat.argsort()[:(k-dead_k)]\n",
    "        live_scores = cand_flat[ranks_flat]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = probs.shape[1]\n",
    "        live_samples = [live_samples[r//voc_size]+[r%voc_size] for r in ranks_flat]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        zombie = [s[-1] == eos or len(s) >= maxsample for s in live_samples]\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]  # remove first label == empty\n",
    "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
    "        dead_k = len(dead_samples)\n",
    "        # remove zombies from the living \n",
    "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
    "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    return live_samples + dead_samples, live_scores + dead_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - BLEU score\n",
    "\n",
    "In this last part, you are going to implement the BLEU score to assess the effectiveness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_simple_nmt(in_chars, out_chars):\n",
    "    inputs = Input(shape=(TIME_STEPS,))\n",
    "    \n",
    "    input_embed = Embedding(in_chars, ENCODER_UNITS * 2, input_length=TIME_STEPS, trainable=True,\n",
    "                            name='embedding')(inputs)\n",
    "    \n",
    "    enc_out = Bidirectional(LSTM(ENCODER_UNITS, return_sequences=True))(input_embed)\n",
    "    dec_out = LSTM(DECODER_UNITS, return_sequences=True)(enc_out)\n",
    "    attention_mul = attention_3d_block(dec_out)\n",
    "    \n",
    "    output = TimeDistributed(Dense(out_chars, activation='softmax'))(attention_mul)\n",
    "   \n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bleu import compute_bleu\n",
    "\n",
    "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
    "GROUND_TRUTH = ['1979-05-03', '2009-04-05', '2016-02-20', '2007-07-10']\n",
    "\n",
    "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
    "    encoded = string_to_int(text, Tx, input_vocabulary)\n",
    "    prediction = model.predict(np.array([encoded]))\n",
    "    prediction = np.argmax(prediction[0], axis=-1)\n",
    "    return int_to_string(prediction, inv_output_vocabulary)\n",
    "\n",
    "def run_examples(model, input_vocabulary, inv_output_vocabulary, samples=(EXAMPLES, GROUND_TRUTH)):\n",
    "    predicted = []\n",
    "    examples, targets = samples\n",
    "    assert len(examples) == len(targets)\n",
    "    \n",
    "    for i, example in enumerate(examples):\n",
    "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
    "        print('input:', example)\n",
    "        print('output:', predicted[i])\n",
    "        print(\"BLEU score: \", compute_bleu([[ch for ch in targets[i]]], [ch for ch in predicted[i]])[0])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_examples(m, human_vocab, inv_machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_map(model, input_vocabulary, inv_output_vocabulary, text):\n",
    "    \"\"\"\n",
    "        visualization of attention map\n",
    "    \"\"\"\n",
    "    # encode the string\n",
    "    encoded = string_to_int(text, Tx, input_vocabulary)\n",
    "\n",
    "    # get the output sequence\n",
    "    prediction = model.predict(np.array([encoded]))\n",
    "    predicted_text = np.argmax(prediction[0], axis=-1)\n",
    "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "\n",
    "    text_ = list(text)\n",
    "    # get the lengths of the string\n",
    "    input_length = len(text)\n",
    "    output_length = predicted_text.index('<pad>')\n",
    "    # get the activation map\n",
    "    attention_vector = get_activations(model, [encoded], layer_name='attention_vec')[0].squeeze()\n",
    "    activation_map = attention_vector[0:output_length, 0:input_length]\n",
    "    \n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(8, 8.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(activation_map, interpolation='nearest', cmap='gray')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Probability', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "    ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_map(m, human_vocab, inv_machine_vocab, EXAMPLES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
